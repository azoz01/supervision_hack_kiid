{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcs(X, Y, factor=20):\n",
    "    # find the length of the strings\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "    \n",
    "    max_error = m // factor\n",
    " \n",
    "    # declaring the array for storing the dp values\n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    "    M = [[None]*(n + 1) for i in range(m + 1)]\n",
    "    \n",
    "    missing_key = [[m]*(n + 1) for i in range(m + 1)]\n",
    "    missing_text = [[n]*(n + 1) for i in range(m + 1)]\n",
    " \n",
    "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
    "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
    "    and Y[0..j-1]\"\"\"\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0 :\n",
    "                L[i][j] = 0\n",
    "                M[i][j] = ''\n",
    "                missing_key[i][j] = m\n",
    "                missing_text[i][j] = n\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1]+1\n",
    "                M[i][j] = M[i-1][j-1] + X[i-1]\n",
    "                missing_key[i][j] = missing_key[i-1][j-1] - 1\n",
    "                missing_text[i][j] = missing_text[i-1][j-1] - 1\n",
    "                \n",
    "            else:\n",
    "                # L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    "                if L[i-1][j] > L[i][j-1]:\n",
    "                    L[i][j] = L[i-1][j]\n",
    "                    M[i][j] = M[i-1][j] + '_'\n",
    "                    missing_key[i][j] = missing_key[i-1][j] \n",
    "                    missing_text[i][j] = missing_text[i-1][j] - 1                \n",
    "                else:\n",
    "                    L[i][j] = L[i][j-1]\n",
    "                    M[i][j] = M[i][j-1] + '^'\n",
    "                    missing_key[i][j] = missing_key[i][j-1] - 1\n",
    "                    missing_text[i][j] = missing_text[i][j-1] \n",
    "                    \n",
    " \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
    "    root = M[m][n][:m+max_error].rstrip('^').rstrip('_')\n",
    "    total_err = root.count('^') + root.count('_')\n",
    "    print(root)\n",
    "    return total_err <= max_error * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'kluczowe informacje dla inwestorów'\n",
    "match = 'duppa kluczowe informacje dla inwestoró 123 dgdfhjdfjgfdjdj  '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kluczowe informacje dla inwestoró_^\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcs(key, match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 123123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_PHRASES_DICT = {\n",
    "    \"Kluczowe informacje dla inwestorów\": \"intro\",\n",
    "    \"Niniejszy dokument zawiera kluczowe informacje dla inwestorów dotyczące tego funduszu. Nie są to materiały marketingowe. Dostarczenie tych informacji jest wymogiem prawnym mającym na celu ułatwienie zrozumienia charakteru i ryzyka związanego z inwestowaniem w ten fundusz. Przeczytanie niniejszego dokumentu jest zalecane inwestorowi, aby mógł on podjąć świadomą decyzję inwestycyjną.\": \"intro\",\n",
    "    \"Niniejsze kluczowe informacje dla inwestorów są aktualne na dzień\": \"informacje praktyczne\",\n",
    "    \"Fundusz otrzymał zezwolenie na prowadzenie działalności w\": \"raw_text\",\n",
    "    \"Zalecenie: niniejszy fundusz może nie być odpowiedni dla inwestorów, którzy planują wycofać swoje środki w ciągu\": \"cele i polityka inwestycyjna\",\n",
    "    \"może zostać pociągnięta do odpowiedzialności za każde oświadczenie zawarte w niniejszym dokumencie, które wprowadza w błąd, jest niezgodne ze stanem faktycznym lub niespójne z odpowiednimi częściami prospektu emisyjnego UCITS.\": \"informacje praktyczne\",\n",
    "    \"Opłaty jednorazowe pobierane przed lub po dokonaniu inwestycji\": \"opłaty\",\n",
    "    \"Opłata za subskrypcję\": \"raw_text\",\n",
    "    \"Opłata za umorzenie\": \"opłaty\",\n",
    "    \"Opłaty pobierane z funduszu w ciągu roku\": \"opłaty\",\n",
    "    \"Opłaty bieżące\": \"opłaty\",\n",
    "    \"Opłaty pobierane z funduszu w określonych warunkach szczególnych\": \"raw_text\",\n",
    "    \"Opłata za wyniki\": \"opłaty\",\n",
    "    \"Cele i polityka inwestycyjna\": \"cele i polityka inwestycyjna\",\n",
    "    \"Profil ryzyka i zysku\": \"profil ryzyka i zysku\",\n",
    "    \"Opłaty\": \"opłaty\",\n",
    "    \"Wyniki osiągnięte w przeszłości\": \"wyniki osiągnięte w przeszłości\",\n",
    "    \"Informacje praktyczne\": \"informacje praktyczne\",\n",
    "}\n",
    "\n",
    "def lcs(X, Y, factor=20):\n",
    "\n",
    "    m = len(X)\n",
    "    n = len(Y)\n",
    "    \n",
    "    max_error = m // factor\n",
    " \n",
    "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
    "    M = [[None]*(n + 1) for i in range(m + 1)]\n",
    "    \n",
    "    missing_key = [[m]*(n + 1) for i in range(m + 1)]\n",
    "    missing_text = [[n]*(n + 1) for i in range(m + 1)]\n",
    "\n",
    "    for i in range(m + 1):\n",
    "        for j in range(n + 1):\n",
    "            if i == 0 or j == 0 :\n",
    "                L[i][j] = 0\n",
    "                M[i][j] = ''\n",
    "                missing_key[i][j] = m\n",
    "                missing_text[i][j] = n\n",
    "            elif X[i-1] == Y[j-1]:\n",
    "                L[i][j] = L[i-1][j-1]+1\n",
    "                M[i][j] = M[i-1][j-1] + X[i-1]\n",
    "                missing_key[i][j] = missing_key[i-1][j-1] - 1\n",
    "                missing_text[i][j] = missing_text[i-1][j-1] - 1\n",
    "                \n",
    "            else:\n",
    "                # L[i][j] = max(L[i-1][j], L[i][j-1])\n",
    "                if L[i-1][j] > L[i][j-1]:\n",
    "                    L[i][j] = L[i-1][j]\n",
    "                    M[i][j] = M[i-1][j] + '_'\n",
    "                    missing_key[i][j] = missing_key[i-1][j] \n",
    "                    missing_text[i][j] = missing_text[i-1][j] - 1                \n",
    "                else:\n",
    "                    L[i][j] = L[i][j-1]\n",
    "                    M[i][j] = M[i][j-1] + '^'\n",
    "                    missing_key[i][j] = missing_key[i][j-1] - 1\n",
    "                    missing_text[i][j] = missing_text[i][j-1] \n",
    "                    \n",
    "            if M[i][j] == X:\n",
    "                return True\n",
    "                    \n",
    " \n",
    "    # L[m][n] contains the length of LCS of X[0..n-1] & Y[0..m-1]\n",
    "    root = M[m][n][:m+max_error].rstrip('^').rstrip('_')\n",
    "    total_err = root.count('^') + root.count('_')\n",
    "    \n",
    "    return total_err <= max_error * 2\n",
    "\n",
    "\n",
    "def check_doc(doc: pd.Series) -> pd.DataFrame:\n",
    "    phrases = []\n",
    "    does_exist = []\n",
    "    for phrase, col in KEY_PHRASES_DICT.items():\n",
    "        text = ' '.join(doc[col].lower().split())\n",
    "        phrase_flat = ' '.join(phrase.lower().split())\n",
    "        res = lcs(phrase_flat, text)\n",
    "        \n",
    "        phrases.append(phrase)\n",
    "        does_exist.append(res)\n",
    "        \n",
    "    df = pd.DataFrame(data={'WYRAZENIE' : phrases, 'FLAGA_WYSTAPIENIA': does_exist})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_docs = pd.read_parquet('../data/parsed/kiids_parsed.parquet')\n",
    "df_docs = df_docs.rename(columns={'filename': 'NAZWA_PLIKU'})\n",
    "df_meta = pd.read_csv('../data/final/Pomysłowi_Inżynierowie_Wielkich_Okazji_KIID_META.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.merge(df_docs, df_meta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'informacje praktyczne\\t'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Dawid\\Anaconda3\\envs\\hack_venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Dawid\\Anaconda3\\envs\\hack_venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Dawid\\Anaconda3\\envs\\hack_venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'informacje praktyczne\\t'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [113], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m df_output \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m df_full\u001b[39m.\u001b[39miterrows():\n\u001b[1;32m----> 3\u001b[0m     df_phrase \u001b[39m=\u001b[39m check_doc(row)\n\u001b[0;32m      4\u001b[0m     df_output \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df_output, df_phrase])\n",
      "Cell \u001b[1;32mIn [111], line 76\u001b[0m, in \u001b[0;36mcheck_doc\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     74\u001b[0m does_exist \u001b[39m=\u001b[39m []\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m phrase, col \u001b[39min\u001b[39;00m KEY_PHRASES_DICT\u001b[39m.\u001b[39mitems():\n\u001b[1;32m---> 76\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(doc[col]\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39msplit())\n\u001b[0;32m     77\u001b[0m     phrase_flat \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(phrase\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39msplit())\n\u001b[0;32m     78\u001b[0m     res \u001b[39m=\u001b[39m lcs(phrase_flat, text)\n",
      "File \u001b[1;32mc:\\Users\\Dawid\\Anaconda3\\envs\\hack_venv\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dawid\\Anaconda3\\envs\\hack_venv\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\Dawid\\Anaconda3\\envs\\hack_venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'informacje praktyczne\\t'"
     ]
    }
   ],
   "source": [
    "df_output = pd.DataFrame()\n",
    "for index, row in df_full.iterrows():\n",
    "    df_phrase = check_doc(row)\n",
    "    df_output = pd.concat([df_output, df_phrase])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('hack_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e98807ee2f3da63852960dc6020a5ec887e95e81874581de0b8e6ab43381f528"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
